{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP With Hotel Review Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please run the imports below in order to set up the environment first.\n",
    "\n",
    "# The usual packages\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# To make our sets\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Scalars\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "\n",
    "# The classifiers \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the NLP with Hotel Review Part 1. Here we will dive into the Exploratory Data Analysts as well as Data Wrangling of the Hotel Review dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please run the code below to read in the following CSV data file.\n",
    "\n",
    "# Contains various Hotel Reviews and other Hotel information.\n",
    "hotelreviews_df = pd.read_csv('data/Hotel_Reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, let us take a look at the Hotel Review dataset that we will be working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To take a peak at the data we are working with.\n",
    "hotelreviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, we can see that the Hotel Review dataset is comprised of a mix of numeric and non-numeric data. We have hotel information such as the hotel address, hotel name, and even the longitude and latitude of the hotel. We have a review date and different review scores along with both positive and negative written text reviews. Our focus for this EDA will be the `Reviewer_Score` which will be our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(515738, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the shape of the dataset.\n",
    "hotelreviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 515738 entries, 0 to 515737\n",
      "Data columns (total 17 columns):\n",
      " #   Column                                      Non-Null Count   Dtype  \n",
      "---  ------                                      --------------   -----  \n",
      " 0   Hotel_Address                               515738 non-null  object \n",
      " 1   Additional_Number_of_Scoring                515738 non-null  int64  \n",
      " 2   Review_Date                                 515738 non-null  object \n",
      " 3   Average_Score                               515738 non-null  float64\n",
      " 4   Hotel_Name                                  515738 non-null  object \n",
      " 5   Reviewer_Nationality                        515738 non-null  object \n",
      " 6   Negative_Review                             515738 non-null  object \n",
      " 7   Review_Total_Negative_Word_Counts           515738 non-null  int64  \n",
      " 8   Total_Number_of_Reviews                     515738 non-null  int64  \n",
      " 9   Positive_Review                             515738 non-null  object \n",
      " 10  Review_Total_Positive_Word_Counts           515738 non-null  int64  \n",
      " 11  Total_Number_of_Reviews_Reviewer_Has_Given  515738 non-null  int64  \n",
      " 12  Reviewer_Score                              515738 non-null  float64\n",
      " 13  Tags                                        515738 non-null  object \n",
      " 14  days_since_review                           515738 non-null  object \n",
      " 15  lat                                         512470 non-null  float64\n",
      " 16  lng                                         512470 non-null  float64\n",
      "dtypes: float64(4), int64(5), object(8)\n",
      "memory usage: 66.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# To get further insights into the dataset.\n",
    "hotelreviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hotel_Address                                    0\n",
       "Additional_Number_of_Scoring                     0\n",
       "Review_Date                                      0\n",
       "Average_Score                                    0\n",
       "Hotel_Name                                       0\n",
       "Reviewer_Nationality                             0\n",
       "Negative_Review                                  0\n",
       "Review_Total_Negative_Word_Counts                0\n",
       "Total_Number_of_Reviews                          0\n",
       "Positive_Review                                  0\n",
       "Review_Total_Positive_Word_Counts                0\n",
       "Total_Number_of_Reviews_Reviewer_Has_Given       0\n",
       "Reviewer_Score                                   0\n",
       "Tags                                             0\n",
       "days_since_review                                0\n",
       "lat                                           3268\n",
       "lng                                           3268\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotelreviews_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the dataset into `hotelreviews_df` and reviewing the above, we can see that the Hotel Reviews dataset has 515,738 rows and 17 columns. The data is comprised of three different datatypes: four `float64`, five `int64`, and eight `object` types. The data file size is 66.9+ KB. We have also checked to see whether there are any null values within our dataset, which appears that there are 3268 missing values in both the `lat` column as well as the `lng` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our data, we can see that the `Reviewer_Score` provided are all given as decimal values (float). In order to convert them into integers (int) from 1 to 10, we will take the data within the `Reviewer_Score` column and round it to the nearest ones place (or whole number) using `.round(0)` and then convert the datatype from float to integer using `.astype()` as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding 'Reviewer_Score' and converting values from the current datatype float into an integer. \n",
    "hotelreviews_df['Reviewer_Score'] = hotelreviews_df['Reviewer_Score'].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we take a look at our data we should see that all of the values within the `Reviewer_Score` column are now whole numbers and the are all of integer datatype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Russia</td>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>397</td>\n",
       "      <td>1403</td>\n",
       "      <td>Only the park outside of the hotel was beauti...</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1403</td>\n",
       "      <td>No real complaints the hotel was great great ...</td>\n",
       "      <td>105</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/31/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>42</td>\n",
       "      <td>1403</td>\n",
       "      <td>Location was good and staff were ok It is cut...</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>[' Leisure trip ', ' Family with young childre...</td>\n",
       "      <td>3 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/31/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>210</td>\n",
       "      <td>1403</td>\n",
       "      <td>Great location in nice surroundings the bar a...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[' Leisure trip ', ' Solo traveler ', ' Duplex...</td>\n",
       "      <td>3 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/24/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>140</td>\n",
       "      <td>1403</td>\n",
       "      <td>Amazing location and building Romantic setting</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Suite ', ' St...</td>\n",
       "      <td>10 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Hotel_Address  \\\n",
       "0   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "1   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "2   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "3   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "4   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "\n",
       "   Additional_Number_of_Scoring Review_Date  Average_Score   Hotel_Name  \\\n",
       "0                           194    8/3/2017            7.7  Hotel Arena   \n",
       "1                           194    8/3/2017            7.7  Hotel Arena   \n",
       "2                           194   7/31/2017            7.7  Hotel Arena   \n",
       "3                           194   7/31/2017            7.7  Hotel Arena   \n",
       "4                           194   7/24/2017            7.7  Hotel Arena   \n",
       "\n",
       "  Reviewer_Nationality                                    Negative_Review  \\\n",
       "0              Russia    I am so angry that i made this post available...   \n",
       "1             Ireland                                         No Negative   \n",
       "2           Australia    Rooms are nice but for elderly a bit difficul...   \n",
       "3      United Kingdom    My room was dirty and I was afraid to walk ba...   \n",
       "4         New Zealand    You When I booked with your company on line y...   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                                397                     1403   \n",
       "1                                  0                     1403   \n",
       "2                                 42                     1403   \n",
       "3                                210                     1403   \n",
       "4                                140                     1403   \n",
       "\n",
       "                                     Positive_Review  \\\n",
       "0   Only the park outside of the hotel was beauti...   \n",
       "1   No real complaints the hotel was great great ...   \n",
       "2   Location was good and staff were ok It is cut...   \n",
       "3   Great location in nice surroundings the bar a...   \n",
       "4    Amazing location and building Romantic setting    \n",
       "\n",
       "   Review_Total_Positive_Word_Counts  \\\n",
       "0                                 11   \n",
       "1                                105   \n",
       "2                                 21   \n",
       "3                                 26   \n",
       "4                                  8   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  \\\n",
       "0                                           7               3   \n",
       "1                                           7               8   \n",
       "2                                           9               7   \n",
       "3                                           1               4   \n",
       "4                                           3               7   \n",
       "\n",
       "                                                Tags days_since_review  \\\n",
       "0  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "1  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "2  [' Leisure trip ', ' Family with young childre...            3 days   \n",
       "3  [' Leisure trip ', ' Solo traveler ', ' Duplex...            3 days   \n",
       "4  [' Leisure trip ', ' Couple ', ' Suite ', ' St...           10 days   \n",
       "\n",
       "         lat       lng  \n",
       "0  52.360576  4.915968  \n",
       "1  52.360576  4.915968  \n",
       "2  52.360576  4.915968  \n",
       "3  52.360576  4.915968  \n",
       "4  52.360576  4.915968  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To peak at the changes made above.\n",
    "hotelreviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To verify that 'Reviewer_Score' is now dataype 'int'.\n",
    "hotelreviews_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the large amount of data we have I would assume that we would have a rather even or balanced distribution of the data among the different reviewer scores ranging from 0 to 10. Let us confirm this by actually taking a look and visualizing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what is the actual distribution of the reviews..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to view this data is to visualize it by creating a histogram and a boxplot which can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a plt subplot grid\n",
    "plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "# Plot out the histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(hotelreviews_df['Reviewer_Score'], bins=20)\n",
    "plt.title('Reviewer Score Distribution')\n",
    "plt.xlabel('Reviewer Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Plot the boxplot. We can use the seaborn boxplot code for this.\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(hotelreviews_df['Reviewer_Score'], color='orange')\n",
    "plt.title('Reviewer Score Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A potential problem with this distribution is that it is very skewed or unbalanced. There is a very large difference between the distribution of the review scores, with over 175,000 reviews with a `Reviewer_Score` of 10 compared to the next highest counts in the amounts of about 110,000 reviews with a `Reviewer_Score` of 8 and about 100,000 with a `Reviewer_Score` of 9. In order to balance out the distribution and 'unskew' the data, we may need to group certain values together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that this dataset has a good mix of numeric and non-numeric columns. We can easily identify which columns are numeric and which are non-numeric, as well as which columns can be turned from non-numeric columns to numeric. Lets take a look at the data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a peak at the data.\n",
    "hotelreviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get further insight into our dataset.\n",
    "hotelreviews_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we can see that the following columns listed below are non-numeric: \n",
    "\n",
    "- Hotel_Address\n",
    "- Review_Date\n",
    "- Hotel_Name\n",
    "- Reviewer_Nationality\n",
    "- Negative_Review\n",
    "- Positive_Review\n",
    "- Tags\n",
    "- days_since_review\n",
    "\n",
    "While the following columns listed below are numeric: \n",
    "\n",
    "- Additional_Number_of_Scoring\n",
    "- Average_Score\n",
    "- Review_Total_Negative_Word_Counts\n",
    "- Total_Number_of_Reviews\n",
    "- Review_Total_Positive_Word_Counts\n",
    "- Total_Number_of_Reviews_Reviewer_Has_Given\n",
    "- Reviewer_Score\n",
    "- lat\n",
    "- lng\n",
    "\n",
    "Based on this we can deduce that 2 of the columns can be changed from a non-numeric column to a numeric column, such as the `days_since_review` column which is currently an object and can be turned into an integer. Along with the `Tags` column which is also an object but can possibly be seperated into several different columns and then we can possibly take those newly created columns and turn them from non-numeric to numeric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Converting the `Reviewer_Score` Column into Binary Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding how review scores generally work we know that there can be a review score with a value anywhere between 0 and 10 within our dataset. Taking a look at the `Reviewer_Score` column, we can see that our dataset currently does not have any review scores of 0 or 1, however it does have values ranging between 2 and 10 as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values within the 'Reviewer_Score' column.\n",
    "reviewvalues = hotelreviews_df['Reviewer_Score'].unique()\n",
    "sorted(reviewvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the below plot of the data, we can see that there is an unbalanced distribution between the different review scores, with over 175,000 reviews with a `Reviewer_Score` of 10 compared to the next highest counts in the amounts of about 110,000 reviews with a `Reviewer_Score` of 8 and about 100,000 with a `Reviewer_Score` of 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the total counts accross the different Reviewer Scores.\n",
    "sns.countplot(hotelreviews_df['Reviewer_Score'],label=\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this information, we can proceed with converting the `Reviewer_Score` column into a binary column in the following way:\n",
    "\n",
    "- Reviews that are below 9 should be encoded as 0 ('not good'). \n",
    "    \n",
    "    `Reviewer_Score` < 9\n",
    "\n",
    "- Reviews with scores 9 and 10 as 1 ('good').\n",
    "\n",
    "    `Reviewer_Score` >= 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'Reviewer_Score' column into a binary column.\n",
    "hotelreviews_df['Reviewer_Score'].values[hotelreviews_df['Reviewer_Score'] < 9] = 0\n",
    "hotelreviews_df['Reviewer_Score'].values[hotelreviews_df['Reviewer_Score'] >= 9] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the dataset with new binary 'Reviewer_Score' column.\n",
    "hotelreviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the total counts accross the different Reviewer Scores again except this time with new binary values.\n",
    "sns.countplot(hotelreviews_df['Reviewer_Score'],label=\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Converting Non-Numeric Columns to Numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the above visualization, we can see that now we have a more even or balanced distribution within our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take another look at our data.\n",
    "hotelreviews_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our data now, we can see that we still have several non-numeric columns as shown below (excluding `Negative_Review` and `Positive_Review`:\n",
    "    \n",
    "- Hotel_Address\n",
    "- Review_Date \n",
    "- Hotel_Name \n",
    "- Reviewer_Nationality  \n",
    "- Tags\n",
    "- days_since_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed with converting the `days_since_review` column from its current object datatype into a numeric column. We can do this by splitting up the column into two columns, one column with the integer (actual number of days) and the second column with the string (the word 'days'). We can then remove the second column as it is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using str.strip to remove 'days' and then converting to numeric by astype.\n",
    "hotelreviews_df['days_since_review'] = hotelreviews_df['days_since_review'].str.strip(' days').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming datatype of 'days_since_review' column.\n",
    "hotelreviews_df['days_since_review'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to our other non-numeric columns, the `Hotel_Address` column will be dropped along with with `Hotel_Name` as these cannot be converted into numerical values given there are far too may different hotel addresses and hotel names. \n",
    "\n",
    "Although normally we would be able to convert `Review_Date` into a numeric column by converting it to a quarterly value representation, we have data spanning muliple different years which would not give us an accurate representation of the review date. For example, we can convert date into values of 1 to 4 representing Q1 to Q4 within a given year however this would mean we no longer know what year that quarter belongs to. Therefore we will also be dropping the `Review_Date` column. \n",
    "\n",
    "The `Reviewer_Nationality` can be assigned a unique number representing each different country, however there are a lot of different countries which would result in having a long list of different values which we would not be able to exactly determine which country those values belong to. Hence, we will also drop this column.\n",
    "\n",
    "`Tags` can be very useful data however it is very messy with regards to order and organization. Although we can split up each string within a given `Tags` row, there is quite a bit of missing data and a lot of organization and cleaning would need to take place in order to actually appropriately arrange the data. For this reason we will also drop this column.\n",
    "\n",
    "To summarize, the following non-numeric columns will be dropped seeing as we cannot convert them into numerical values:\n",
    "\n",
    "- Hotel_Address\n",
    "- Review_Date \n",
    "- Hotel_Name \n",
    "- Reviewer_Nationality  \n",
    "- Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the remianing non-numeric columns.\n",
    "hotelreviews_df = hotelreviews_df.drop(['Hotel_Address', 'Review_Date', 'Hotel_Name', 'Reviewer_Nationality', 'Tags'], axis=1)\n",
    "hotelreviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Splitting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned and oragnized our data, we can proceed with splitting our data into our Train and Test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning our features to X.\n",
    "X = hotelreviews_df.drop(['Reviewer_Score'], axis=1)\n",
    "\n",
    "# Assigning our target to y. \n",
    "y = hotelreviews_df['Reviewer_Score']\n",
    "\n",
    "# Check \n",
    "display(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our training and test sets, 20% test size, random state of 5.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5, stratify=y)\n",
    "\n",
    "# Check \n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Using CountVectorizer to combine Positive_Review and Negative_Review with the numeric data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we must instantiate, fit, and transform our X_train data using the CountVectorizer using the min_df parameter for the purpose of ignoring words that have very few occurrences to be considered meaningful. Lets start with the `Positive_Review` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate \n",
    "bagofwords = CountVectorizer(min_df=500)\n",
    "\n",
    "# 2. Fit \n",
    "bagofwords.fit(X_train[\"Positive_Review\"])\n",
    "\n",
    "# 3. Transform\n",
    "X_train_positive_transformed = bagofwords.transform(X_train[\"Positive_Review\"])\n",
    "X_train_positive_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a sparse matrix for `Positive_Review` with a total of 412,590 rows and 999 columns. This means that there are 999 unique terms or tokens.\n",
    "\n",
    "Next we need to convert this sparse matrix into a numpy array in order to later combine the sparse matrix with the numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the sparse matrix into a numpy array\n",
    "X_train_positive_transformed = X_train_positive_transformed.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_positive_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same has to be done with the `Negative_Review` column as was done with the `Positive_Review` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate \n",
    "bagofwords = CountVectorizer(min_df=500)\n",
    "\n",
    "# 2. Fit \n",
    "bagofwords.fit(X_train[\"Negative_Review\"])\n",
    "\n",
    "# 3. Transform\n",
    "X_train_negative_transformed = bagofwords.transform(X_train[\"Positive_Review\"])\n",
    "X_train_negative_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a sparse matrix for `Negative_Review` with a total of 412,590 rows and 1199 columns. This means that there are 1199 unique terms or tokens.\n",
    "\n",
    "Next we need to convert this sparse matrix into a numpy array in order to later combine the sparse matrix with the numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the sparse matrix into a numpy array\n",
    "X_train_negative_transformed = X_train_negative_transformed.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_negative_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must now also do the same to our Test data. This is because when we train a model on some training data and want to test the same model, the testing data has to be in the exact same format as the training data. This means that the train and test data have to contain the same features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bag-of-words vectorizer fitted to our training data to transform our test data as well for 'Positive_Review'.\n",
    "X_test_positive_transformed = bagofwords.transform(X_test)\n",
    "X_test_positive_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bag-of-words vectorizer fitted to our training data to transform our test data as well for 'Negative_Review'.\n",
    "X_test_negative_transformed = bagofwords.transform(X_test)\n",
    "X_test_negative_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to combine the three matrices (numeric data, positive matrix, and negative matrix):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((X_train, X_train_positive_transformed, X_train_negative_transformed), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us do the same again for the Test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((X_test, X_test_positive_transformed, X_test_negative_transformed), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What does the min_df parameter do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as seen above, adding a min_df parameter to our count vectorizer allows us to exclude any token that occurs in less than min_df documents specified. Min_df is used for the purpose of ignoring words that have very few occurrences to be considered meaningful. For example, in the `Positive_Review` or `Negative_Review` columns we may have a word that appears in only 1 or two rows. Depending on how large our dataset is, we may qualify this as noise and eliminate it from further analysis by utilizing the min_df parameter. I used the min_df parameter above, and depending what you set the min_df parameter equal to, the higher the number the less columns will be present within the sparce matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
